{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Installing and importing libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T16:10:07.795892Z","iopub.status.busy":"2024-09-04T16:10:07.795075Z","iopub.status.idle":"2024-09-04T16:10:26.581048Z","shell.execute_reply":"2024-09-04T16:10:26.579832Z","shell.execute_reply.started":"2024-09-04T16:10:07.795818Z"},"trusted":true},"outputs":[],"source":["!pip install -q bitsandbytes accelerate\n","!pip install evaluate\n","!pip install deepeval"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T16:10:26.628035Z","iopub.status.busy":"2024-09-04T16:10:26.627625Z","iopub.status.idle":"2024-09-04T16:14:35.640319Z","shell.execute_reply":"2024-09-04T16:14:35.639472Z","shell.execute_reply.started":"2024-09-04T16:10:26.627991Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","import torch\n","import torch.nn as nn\n","import bitsandbytes as bnb\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n","from datasets import load_dataset\n","from tqdm import tqdm\n","\n","# Load the fine tuned model\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"shlokjain0177/SuperiorLLM\",\n","    torch_dtype=torch.float16,\n","    device_map='auto',\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"shlokjain0177/SuperiorLLM\")"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the HellaSwag dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T16:34:44.834457Z","iopub.status.busy":"2024-09-04T16:34:44.833710Z","iopub.status.idle":"2024-09-04T16:34:44.879040Z","shell.execute_reply":"2024-09-04T16:34:44.877750Z","shell.execute_reply.started":"2024-09-04T16:34:44.834416Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"hellaswag\" , split=\"validation\")"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluating on HellaSwag dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-09-04T16:17:24.867511Z","iopub.status.busy":"2024-09-04T16:17:24.867196Z","iopub.status.idle":"2024-09-04T16:24:01.941928Z","shell.execute_reply":"2024-09-04T16:24:01.940181Z","shell.execute_reply.started":"2024-09-04T16:17:24.867479Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["def evaluate_model_on_hellaswag(model, tokenizer, dataset):\n","    correct = 0\n","    total = 0\n","\n","    for example in tqdm(dataset):\n","        # The prompt is the concatenation of 'ctx_a' and 'ctx_b'\n","        prompt = example['ctx_a'] + example['ctx_b']\n","        \n","        # Each option is a possible continuation of the prompt\n","        options = example['endings']\n","        correct_option = example[\"label\"]\n","\n","        scores = []\n","        for opt in options:\n","            # Concatenate the prompt with each option\n","            input_text = prompt + \" \" + opt\n","            \n","            # Tokenize the entire sequence\n","            encoding = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n","            input_ids = encoding.input_ids.to(model.device)\n","            attention_mask = encoding.attention_mask.to(model.device)\n","\n","            # Generate model outputs\n","            with torch.no_grad():\n","                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","                logits = outputs.logits\n","\n","            # Compute the score for the option (e.g., using logits)\n","            scores.append(logits.mean().item())  # Example scoring method\n","\n","        # Find the index of the highest score\n","        predicted_option = scores.index(max(scores))\n","\n","        if predicted_option == correct_option:\n","            correct += 1\n","        total += 1\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","# Evaluate the model\n","accuracy = evaluate_model_on_hellaswag(model, tokenizer, dataset)\n","print(f\"HellaSwag Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# clear GPU for loading next model\n","del model\n","import gc\n","gc.collect()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-04T16:24:01.942846Z","iopub.status.idle":"2024-09-04T16:24:01.943264Z","shell.execute_reply":"2024-09-04T16:24:01.943102Z","shell.execute_reply.started":"2024-09-04T16:24:01.943083Z"},"trusted":true},"outputs":[],"source":["# evaluating SuperLLM on HellaSwag dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from datasets import load_dataset\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","\n","# Load the HellaSwag dataset\n","dataset = load_dataset(\"hellaswag\", split=\"validation\")\n","\n","# Load the tokenizer and model\n","model_name = \"qu-bit/SuperLLM\"  # Replace with the correct model path or name\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    torch_dtype=torch.float16,\n","    device_map='auto'\n",")\n","model.eval()\n","\n","def evaluate_model_on_hellaswag(model, tokenizer, dataset, batch_size=8):\n","    correct = 0\n","    total = 0\n","\n","    for i in tqdm(range(0, len(dataset), batch_size)):\n","        batch = dataset[i:i+batch_size]\n","        prompts = [example['ctx_a'] + example['ctx_b'] for example in batch]\n","        options_list = [example['endings'] for example in batch]\n","        correct_options = [example['label'] for example in batch]\n","\n","        # Prepare inputs\n","        all_input_texts = []\n","        for prompts, options in zip(prompts, options_list):\n","            all_input_texts.extend([prompts + \" \" + opt for opt in options])\n","\n","        encodings = tokenizer(all_input_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n","        input_ids = encodings.input_ids.to(model.device)\n","        attention_mask = encodings.attention_mask.to(model.device)\n","\n","        # Generate model outputs\n","        with torch.no_grad():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","\n","        # Compute scores\n","        logits = logits.view(len(batch), -1, logits.size(-1))  # Reshape for batch processing\n","        scores = logits.mean(dim=-1).cpu().numpy()\n","\n","        # Determine predictions\n","        for idx, (options, correct_option) in enumerate(zip(options_list, correct_options)):\n","            option_scores = scores[idx*len(options):(idx+1)*len(options)]\n","            predicted_option = np.argmax(option_scores)\n","            if predicted_option == correct_option:\n","                correct += 1\n","            total += 1\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","# Evaluate the model\n","accuracy = evaluate_model_on_hellaswag(model, tokenizer, dataset)\n","print(f\"HellaSwag Accuracy: {accuracy:.4f}\")\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
